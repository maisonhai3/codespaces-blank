#!/bin/bash

# Master test runner - runs all tests and generates comparison report

source "$(dirname "$0")/common.sh"

COMPARISON_REPORT="$RESULTS_DIR/comparison-report.md"

main() {
    log_info "Starting comprehensive Log Collector PoC..."
    
    # Ensure clean environment
    cleanup
    
    # Create results directory
    mkdir -p "$RESULTS_DIR"
    
    # Initialize comparison report
    initialize_comparison_report
    
    # Test each tool
    test_tool "fluent-bit"
    test_tool "filebeat" 
    test_tool "vector"
    test_tool "logstash"
    
    # Generate final comparison
    generate_comparison_summary
    
    log_success "All tests completed! See comparison report: $COMPARISON_REPORT"
}

initialize_comparison_report() {
    cat > "$COMPARISON_REPORT" << 'EOF'
# Log Collector PoC - Comparison Report

**Test Date:** $(date '+%Y-%m-%d %H:%M:%S')
**Objective:** Compare Fluent Bit, Filebeat, Vector, and Logstash for AiScout edge deployment

## Executive Summary

This PoC tested 4 log collection tools across 3 critical scenarios:
1. **Baseline Performance** - Normal operation resource usage and throughput
2. **Offline Resilience** - Behavior during network disruptions  
3. **Backpressure Handling** - High-load performance and memory management

## Test Environment

- **Platform:** Docker Compose on Ubuntu 24.04.2 LTS
- **Log Format:** JSON (AiScout format simulation)
- **Destination:** Elasticsearch 8.11.0
- **Network:** Bridge network with simulated disruptions
- **Monitoring:** Docker stats every 5 seconds

## Individual Test Results

EOF
}

test_tool() {
    local tool=$1
    log_info "Testing $tool..."
    
    # Run the test
    if ./scripts/test-${tool}.sh; then
        log_success "$tool tests completed successfully"
        
        # Add link to individual report
        echo "- [$tool Results](${tool}-results.md)" >> "$COMPARISON_REPORT"
    else
        log_error "$tool tests failed!"
        echo "- [$tool Results](${tool}-results.md) - **FAILED**" >> "$COMPARISON_REPORT"
    fi
    
    # Wait between tests to let system settle
    log_info "Waiting 30 seconds before next test..."
    sleep 30
}

generate_comparison_summary() {
    cat >> "$COMPARISON_REPORT" << 'EOF'

## Comparison Summary

### Performance Metrics Comparison

| Tool | Baseline CPU (%) | Baseline Memory | Throughput (logs/s) | Recovery Time (s) | High-Load CPU (%) |
|------|------------------|-----------------|---------------------|-------------------|-------------------|
| Fluent Bit | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] |
| Filebeat | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] |
| Vector | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] |
| Logstash | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] | [Auto-populated] |

### Qualitative Assessment

#### Configuration Complexity
- **Fluent Bit:** Simple INI-style configuration, good for basic use cases
- **Filebeat:** YAML configuration, well-documented, Elastic ecosystem integration
- **Vector:** TOML configuration, modern approach, good observability features
- **Logstash:** Ruby DSL, powerful but complex, steep learning curve

#### Documentation & Community
- **Fluent Bit:** Good documentation, CNCF project, active community
- **Filebeat:** Excellent documentation, strong Elastic support, large community
- **Vector:** Modern documentation, growing community, observability-focused
- **Logstash:** Comprehensive documentation, mature ecosystem, extensive plugins

#### Edge Device Suitability
- **Resource Efficiency:** [Based on test results]
- **Offline Capabilities:** [Based on test results]
- **Configuration Simplicity:** [Based on assessment]
- **Maintenance Overhead:** [Based on assessment]

## Recommendations

### For AiScout Edge Deployment:

**Primary Recommendation:** [To be filled based on results]

**Reasoning:**
- Performance characteristics align with edge device constraints
- Offline resilience meets requirements
- Configuration complexity manageable for operations team
- Resource usage optimized for edge deployment

**Alternative Option:** [To be filled based on results]

**Implementation Considerations:**
1. Container resource limits and monitoring
2. Log rotation and disk space management
3. Network retry and buffering configuration
4. Observability and health check setup

## Next Steps

1. **Production Pilot:** Deploy recommended solution in controlled environment
2. **Monitoring Setup:** Implement comprehensive monitoring and alerting
3. **Documentation:** Create deployment and operations guides
4. **Training:** Prepare operations team for new tool

---

*Generated by Log Collector PoC Test Suite*
*Test Duration: Approximately 4-5 hours for complete suite*
EOF
    
    log_info "Comparison report template created"
    log_info "Manual completion required for specific metrics and recommendations"
}

# Check dependencies
check_dependencies() {
    local missing_deps=()
    
    command -v docker >/dev/null 2>&1 || missing_deps+=("docker")
    command -v docker-compose >/dev/null 2>&1 || missing_deps+=("docker-compose")
    command -v jq >/dev/null 2>&1 || missing_deps+=("jq")
    command -v bc >/dev/null 2>&1 || missing_deps+=("bc")
    
    if [ ${#missing_deps[@]} -gt 0 ]; then
        log_error "Missing dependencies: ${missing_deps[*]}"
        log_error "Please install missing dependencies and try again"
        exit 1
    fi
}

# Pre-flight checks
preflight_checks() {
    log_info "Running pre-flight checks..."
    
    # Check dependencies
    check_dependencies
    
    # Check Docker daemon
    if ! docker info >/dev/null 2>&1; then
        log_error "Docker daemon is not running"
        exit 1
    fi
    
    # Check available disk space (at least 5GB)
    local available_space=$(df . | awk 'NR==2 {print $4}')
    if [ "$available_space" -lt 5242880 ]; then  # 5GB in KB
        log_warning "Available disk space is less than 5GB. Tests may fail."
    fi
    
    log_success "Pre-flight checks passed"
}

# Handle script interruption
cleanup_on_exit() {
    log_warning "Script interrupted. Cleaning up..."
    cleanup
    exit 1
}

trap cleanup_on_exit INT TERM

# Run preflight checks first
preflight_checks

# Run main function
main "$@"
